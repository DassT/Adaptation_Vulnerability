library("moments")
### get the SMI data directly from yahoo finance
MyData   <- getSymbols("AMZN", auto.assign=FALSE, from="1990-01-01", src='yahoo')
head(MyData)
#### important NOTE MyData comes as an xts object
#### an extensible ts object. in short it is a matrix with a time index !
is.xts(MyData)
price = MyData$AMZN.Close
idx   = !is.na(price)
price = price[idx]
autoplot(price)
## TASK 1:
# now compute log returns
# delete the "na" (for later purposes)
# plot returns
# now plot returns
ret <- diff(log(price))
idx   = !is.na(ret)
ret = ret[idx]
autoplot(ret) + labs(title="AMZN",
subtitle="Returns",
x ="time") +
theme(panel.grid.minor = element_blank())
##       y =expression(Delta),
## TASK 2
# Compute descriptive statistics on ret:
# use functions from the library 'moments'
# some descriptive statistics on ret:
sumStat <- c(length(ret), min(ret), max(ret), mean(ret), median(ret), sqrt(var(ret)), skewness(ret), kurtosis(ret)  )
print("# elements, min, max, mean, median, std, skew, kurtosis (not excess kurtosis)", quote = FALSE)
cat(sumStat)
# we now compare against normality
# plot a histogram of returns and compare with the a density generated
# from normal variates with same mean and variance:
hist(ret,
100,
prob = TRUE,
col="gray", main = "Histogram", xlab="AMZN returns")
lines( sort(as.numeric(ret)), dnorm(sort(as.numeric(ret)), mean = mean(as.numeric(ret)),
sd = sqrt(var(as.numeric(ret)))),
lwd = 2, col = "red"
)
## TASK 3 do a qqplot on returns
## use qqnorm
qqnorm(ret)
qqline(ret, col=2)
## TASK 4:
# do a Jarque Bera test to test for normality
# use the function jarque.bera.test from the package 'tseries'
jarque.bera.test(ret)
## TASK 5:
# Compute unconditional (daily) volatility
# Compute unconditional monthly, annualized volatility
sd(ret)
sd(ret*sqrt(21)) #monthly
sd(ret*sqrt(252))#yearly
sd(ret)*sqrt(252)
## TASK 6:
# Compute rolling window 30d volatiliy
# Compute eqma  volatiliy
ret2   <- as.numeric(ret^2) ## need to convert to numeric because otherwise loop below fails
N      <- length(ret)
vol30d <- numeric(N)
lambda <-  0.94;
ewma   <- numeric(N)
for (i in 31:N){
vol30d[i] <- sqrt(var(ret[(i-30):i]))
tmp <- ret2[i:1];
ewma[i] <- (1-lambda)*sum((lambda^(0:(i-1)))*tmp)
}
n <- length(ret2)  #gpt version do not trust
vol <- rep(NA,n)
for (i in 30:n) {
vol[i] <- sqrt(30)*sd(ret2[(i-29):i])
}
## compute a for loop here which fills vol30d and ewma:
## ewma has variance unit; convert ewma to vol !
tmp     <- xts(order.by=index(ret))
allVola <- merge(tmp, vol30d=vol30d)
allVola <- merge(allVola, ewma=ewma)
autoplot(allVola[31:N])
## check how different ewma is vis-a-vis vol30d
autoplot(allVola[,1]-allVola[,2])
acf(ret)
acf(log(ret))
acf(ret^2)
acf(abs(ret))
library("fGarch")
install.packages("fGarch")
library("fGarch")
condDist <- "norm"
q <- 1
gfit01 <- garchFit(formula = ~garch(1,0), data = ret, cond.dist = condDist)
summary(gfit01)
# close windows, clear variables
rm(list = ls(all = TRUE))
graphics.off()
# install and load packages
libraries = c("kernlab", "ellipse", "xtable")
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
install.packages(x)
})
lapply(libraries, library, quietly = TRUE, character.only = TRUE)
################################################################################
########################## manipulate subroutine specc #########################
#################### to return eigenvalues and eigenvectors ####################
################################################################################
setGeneric("specc",function(x, ...) standardGeneric("specc"))
setMethod("specc", signature(x = "formula"),
function(x, data = NULL, na.action = na.omit, ...)
{
mt = terms(x, data = data)
if(attr(mt, "response") > 0) stop("response not allowed in formula")
attr(mt, "intercept") = 0
cl                    = match.call()
mf                    = match.call(expand.dots = FALSE)
mf$formula            = mf$x
mf$...                = NULL
mf[[1]]               = as.name("model.frame")
mf                    = eval(mf, parent.frame())
na.act                = attr(mf, "na.action")
x                     = model.matrix(mt, mf)
res                   = specc(x, ...)
cl[[1]] = as.name("specc")
if(!is.null(na.act)) n.action(res) = na.action ;
return(res)
})
setMethod("specc", signature(x = "matrix"),
function(x, centers, kernel = "rbfdot", kpar = "automatic", nystrom.red = FALSE,
nystrom.sample = dim(x)[1]/6, iterations = 200, mod.sample = 0.75,
na.action = na.omit, ...)
{
x    = na.action(x)
rown = rownames(x)
x    = as.matrix(x)
m    = nrow(x)
if (missing(centers)) stop("centers must be a number or a matrix");
if (length(centers) == 1) {
nc =  centers
if (m < centers) stop("more cluster centers than data points.");
}
else nc = dim(centers)[2];
if(is.character(kpar)) {
kpar = match.arg(kpar, c("automatic", "local"))
if(kpar == "automatic") {
if (nystrom.red == TRUE) {
sam = sample(1:m, floor(mod.sample * nystrom.sample))
}else {
sam = sample(1:m, floor(mod.sample * m))
}
sx   = unique(x[sam, ])
ns   = dim(sx)[1]
dota = rowSums(sx * sx) / 2
ktmp = crossprod(t(sx))
for (i in 1:ns) ktmp[i, ] = 2 * (-ktmp[i, ] + dota + rep(dota[i], ns));
## fix numerical prob.
ktmp[ktmp < 0] = 0
ktmp           = sqrt(ktmp)
kmax           = max(ktmp)
kmin           = min(ktmp + diag(rep(Inf,dim(ktmp)[1])))
kmea           = mean(ktmp)
lsmin          = log2(kmin)
lsmax          = log2(kmax)
midmax         = min(c(2 * kmea, kmax))
midmin         = max(c(kmea/2, kmin))
rtmp           = c(seq(midmin, 0.9 * kmea, 0.05 * kmea),
seq(kmea, midmax, 0.08 * kmea))
if ((lsmax - (Re(log2(midmax)) + 0.5)) < 0.5) {
step = (lsmax - (Re(log2(midmax)) + 0.5))
} else {
step = 0.5
}
if (((Re(log2(midmin))-0.5)-lsmin) < 0.5 ) {
stepm = ((Re(log2(midmin)) - 0.5) - lsmin)
} else {
stepm = 0.5
}
tmpsig = c(2^(seq(lsmin, (Re(log2(midmin)) - 0.5), stepm)),
rtmp, 2^(seq(Re(log2(midmax)) + 0.5, lsmax,step)))
diss   = matrix(rep(Inf,length(tmpsig) * nc), ncol = nc)
for (i in 1:length(tmpsig)){
ka       = exp((-(ktmp^2)) / (2 * (tmpsig[i]^2)))
diag(ka) = 0
d        = 1 / sqrt(rowSums(ka))
if(!any(d == Inf) && !any(is.na(d)) && (max(d)[1] - min(d)[1] < 10^4)) {
l         = d * ka %*% diag(d)
xi        = eigen(l, symmetric = TRUE)$vectors[, 1:nc]
yi        = xi / sqrt(rowSums(xi^2))
res       = kmeans(yi, centers, iterations)
diss[i, ] = res$withinss
}
}
ms     = which.min(rowSums(diss))
kernel = rbfdot((tmpsig[ms]^(-2))/2)
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (kpar=="local") {
if (nystrom.red == TRUE) {
stop ("Local Scaling not supported for nystrom reduction.")
}
s    = rep(0, m)
dota = rowSums(x * x) / 2
dis  = crossprod(t(x))
for (i in 1:m) dis[i, ]= 2 * (-dis[i, ] + dota + rep(dota[i], m));
## fix numerical prob.
dis[dis < 0] = 0
for (i in 1:m) s[i] = median(sort(sqrt(dis[i, ]))[1:5]);
## Compute Affinity Matrix
km     = exp(-dis / s%*%t(s))
kernel = "Localy scaled RBF kernel"
}
} else {
if(!is(kernel, "kernel")) {
if(is(kernel, "function")) kernel = deparse(substitute(kernel));
kernel = do.call(kernel, kpar)
}
if(!is(kernel, "kernel")) stop("kernel must inherit from class `kernel'");
## Compute Affinity Matrix
if (nystrom.red == FALSE) km = kernelMatrix(kernel, x);
}
if (nystrom.red == TRUE){
n      = floor(nystrom.sample)
ind    = sample(1:m, m)
x      = x[ind, ]
tmps   = sort(ind, index.return = TRUE)
reind  = tmps$ix
A      = kernelMatrix(kernel, x[1:n, ])
B      = kernelMatrix(kernel, x[-(1:n), ], x[1:n, ])
d1     = colSums(rbind(A, B))
d2     = rowSums(B) + drop(matrix(colSums(B), 1) %*% .ginv(A) %*% t(B))
dhat   = sqrt(1 / c(d1, d2))
A      = A * (dhat[1:n] %*% t(dhat[1:n]))
B      = B * (dhat[(n + 1):m] %*% t(dhat[1:n]))
Asi    = .sqrtm(.ginv(A))
Q      = A + Asi %*% crossprod(B) %*% Asi
tmpres = svd(Q)
U      = tmpres$u
L      = tmpres$d
V      = rbind(A, B) %*% Asi %*% U %*% .ginv(sqrt(diag(L)))
yi     = matrix(0, m, nc)
# for(i in 2:(nc +1)) yi[,i-1] = V[,i]/V[,1];
## specc
for(i in 1:nc) yi[, i] = V[, i]/sqrt(sum(V[, i]^2));
res = kmeans(yi[reind, ], centers, iterations)
} else {
if(is(kernel)[1] == "rbfkernel") diag(km) = 0;
d   = 1 / sqrt(rowSums(km))
l   = d * km %*% diag(d)
xu  = eigen(l)$values[1:nc]
xi  = eigen(l)$vectors[, 1:nc]
xxu = eigen(l)$values
xxi = eigen(l)$vectors
yi  = xi / sqrt(rowSums(xi^2))
res = kmeans(yi, centers, iterations)
}
ll                 = function(l) colMeans(x[which(res$cluster==l), ])
cent               = matrix(unlist(lapply(1:nc, ll)), ncol = dim(x)[2], byrow = TRUE)
ll                 = function(l) sum((x[which(res$cluster == l),] - cent[l, ])^2);
withss             = unlist(lapply(1:nc, ll))
names(res$cluster) = rown
return(new("specc", .Data = list(data = res$cluster, evalues = xxu, evectors = xxi),
size = res$size, centers = cent, withinss = withss, kernelf = kernel))
})
###########################################################################
############################## main computation ###########################
###########################################################################
set.seed(1)
# define eight points
eight   = cbind(c(-3, -2, -2, -2, 1, 1, 2, 4), c(0, 4, -1, -2, 4, 2, -4, -3))
eight   = eight[c(8, 7, 3, 1, 4, 2, 6, 5), ]
sc      = specc(eight, centers = 2)
centers = attr(sc, "centers") # center coordinates
size    = attr(sc, "size")    # size of clusters
datacl  = sc$data             # clusters
evalues = sc$evalues          # eigenvalues
evectors= sc$evectors         # eigenvectors
# Latex export
xtable(as.matrix(evalues))
xtable(evectors)
# final output
plot(eight, type = "n", xlab = "price conciousness", ylab = "brand loyalty",
xlim = c(-4, 4), main = "8 points")
points(eight, pch = 21, cex = 2.7, bg = "white")
text(eight, as.character(1:8), col = "red3", xlab = "first coordinate",
ylab = "second coordinate", main = "8 points", cex = 1)
lines(ellipse(0.6, centre = centers[2, ], scale = c(1.2, 2)), col = "red3", lwd = 2)
lines(ellipse(0.6, centre = centers[1, ], scale = c(.7, .4)), col = "blue3",lwd = 2)
eight
# clear all variables
rm(list = ls(all = TRUE))
graphics.off()
# Drug data
zi = rbind(c(1, 0, 1, 0, 1, 0, 0, 0, 0, 21), c(1, 0, 1, 0, 0, 1, 0, 0, 0, 32), c(1,
0, 1, 0, 0, 0, 1, 0, 0, 70), c(1, 0, 1, 0, 0, 0, 0, 1, 0, 43), c(1, 0, 1, 0,
0, 0, 0, 0, 1, 19), c(1, 0, 0, 1, 1, 0, 0, 0, 0, 683), c(1, 0, 0, 1, 0, 1, 0,
0, 0, 596), c(1, 0, 0, 1, 0, 0, 1, 0, 0, 705), c(1, 0, 0, 1, 0, 0, 0, 1, 0, 295),
c(1, 0, 0, 1, 0, 0, 0, 0, 1, 99), c(0, 1, 1, 0, 1, 0, 0, 0, 0, 46), c(0, 1, 1,
0, 0, 1, 0, 0, 0, 89), c(0, 1, 1, 0, 0, 0, 1, 0, 0, 169), c(0, 1, 1, 0, 0,
0, 0, 1, 0, 98), c(0, 1, 1, 0, 0, 0, 0, 0, 1, 51), c(0, 1, 0, 1, 1, 0, 0,
0, 0, 738), c(0, 1, 0, 1, 0, 1, 0, 0, 0, 700), c(0, 1, 0, 1, 0, 0, 1, 0,
0, 847), c(0, 1, 0, 1, 0, 0, 0, 1, 0, 336), c(0, 1, 0, 1, 0, 0, 0, 0, 1,
196))
y = zi[, 10]
# Design matrix
I = 2  # sex M - F
J = 2  # drug Yes - No
K = 5  # age category 16-29, 30-44, 45-64, 65-74, 75++
# Mean age per group: for Men and for Women
average = c(c(23.2, 36.5, 54.3, 69.2, 79.5), c(23.2, 36.5, 54.3, 69.2, 79.5))
X   = rbind(c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, 1), c(1, -1), c(1, -1), c(1, -1),
c(1, -1), c(1, -1))
X1  = cbind(X, average)  # Xi=design matrix for group i=1,2
n   = dim(X1)
n1  = n[1]
n2  = n[2]
df  = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]  # nijk is the effective in each cell, i=1,2
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)  # current value of beta
# max likelihood in logistic models for 3-way contingency tables
ff = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X1 %*% b0))))
}
(b      = optim(b0, ff)$par)
loglik  = optim(b0, ff)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X1 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X1 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df)
(G2     = 2 * sum(nobs * e))
(pvalG2 = 1 - pchisq(G2, df))
(chi2   = sum(((nobs - nfit)^2)/nfit))
(pvalG2 = 1 - pchisq(G2, df))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
plot(X1[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X1[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X1[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X1[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# logistic model with curvature term: log(y)~gender + age + age^2
(X2 = cbind(X, average, average * average))
n   = dim(X2)
n1  = n[1]
n2  = n[2]
df2 = n1 - n2
label = zi[, 3] == 1
n1jk  = y[label]
label = zi[, 3] == 0
n2jk  = y[label]
b0 = 0 * rep(1, n2)
f2 = function(b0) {
-sum(n1jk * log(matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*%
b0)))) - sum(n2jk * log(matrix(1, dim(matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0)))) - matrix(1, length(n1jk), 1)/(matrix(1,
length(n1jk), 1) + exp(-X2 %*% b0))))
}
(b = optim(b0, f2)$par)
loglik  = optim(b0, f2)$value
N       = sum(y)
p1      = matrix(1, length(n1jk), 1)/(matrix(1, length(n1jk), 1) + exp(-X2 %*% b))
p2      = matrix(1, length(n2jk), 1)/(matrix(1, length(n2jk), 1) + exp(X2 %*% b))
nfit    = rbind((n1jk + n2jk) * p1, (n1jk + n2jk) * p2)
nobs    = c(n1jk, n2jk)
e       = log(nobs) - log(nfit)
print("degree of freedom")
print(df2)
(GG2      = 2 * sum(nobs * e))
(pvalGG2  = 1 - pchisq(GG2, df2))
(chi2     = sum(((nobs - nfit)^2)/nfit))
(pvalG2   = 1 - pchisq(GG2, df2))
print(" ")
print("  observed    fitted")
print("    values    values")
cbind(nobs, nfit)
print(" ")
oddratfit = log(p1/p2)
oddrat    = log(n1jk/n2jk)
dev.new()
plot(X2[1:K, 3], oddratfit[1:K], type = "l", ylim = c(-3.5, -0.5), ylab = "", xlab = "",
lwd = 2)
par(new = TRUE)
plot(X2[(K + 1):(2 * K), 3], oddratfit[(K + 1):(2 * K)], type = "l", ylim = c(-3.5,
-0.5), xlab = "Age category", ylab = "log of odds-ratios", lwd = 2)
points(X2[1:K, 3], oddrat[1:K], pch = "*", cex = 2, col = "red3")
points(X2[(K + 1):(2 * K), 3], oddrat[(K + 1):(2 * K)], cex = 2, col = "blue3")
title(paste("Fit of the log of the odds-ratios "))
# test model one against model two
print("degree of freedom")
print(df - df2)
(overallG2  = G2 - GG2)
(pvaloG2    = 1 - pchisq(overallG2, df - df2))
# clear all variables
rm(list = ls(all = TRUE))
graphics.off()
# Intercity road distances
ber  = c(0, 214, 279, 610, 596, 237)
dre  = c(214, 0, 492, 533, 496, 444)
ham  = c(279, 492, 0, 520, 772, 140)
kob  = c(610, 533, 520, 0, 521, 687)
mue  = c(596, 496, 772, 521, 0, 771)
ros  = c(237, 444, 140, 687, 771, 0)
dist = cbind(ber, dre, ham, kob, mue, ros)
# a, b, h, i, r, x, xx1, xx2 are matrices
a    = (dist^2) * (-0.5)
i    = diag(6)
u    = rep(1, 6)
h    = i - (1/6 * (u %*% t(u)))
b    = h %*% a %*% h             # Determine the inner product matrix
e    = eigen(b)
g1   = cbind(e$vectors[, 1], -e$vectors[, 2])
g2   = diag(e$values[1:2])
xx1  = g1 %*% (g2^0.5)           # Determine the coordinate matrix
x    = cos(pi/2)
y    = sin(pi/2)
z    = -sin(pi/2)
r1   = c(x, z)
r2   = c(y, x)
r    = rbind(r1, r2)
xx2  = xx1 %*% r
xx   = cbind((xx2[, 1] * (-1)) + 500, xx2[, 2] + 500)
# Plot: Map of German Cities
plot(xx[, 1], xx[, 2], xlim = c(0, 900), ylim = c(0, 900), xlab = "EAST - WEST - DIRECTION in km",
ylab = "NORTH - SOUTH - DIRECTION in km", main = "Map of German Cities", cex.axis = 1.2,
cex.lab = 1.2, cex.main = 1.8)
text(xx[, 1], xx[, 2], labels = c("Berlin", "Dresden", "Hamburg", "Koblenz", "Muenchen",
"Rostock"), pos = 4, col = "blue")
View(r)
View(xx1)
library(AER)
library(mhurdle)
install.packages("mhurdle")
setwd("C:/Users/timda/repo/thesis/Adaptation_Vulnerability")
library(mhurdle)
library(tidyverse)
library(texreg)
knitr::opts_chunk$set(echo = TRUE)
df <- read.csv2("training", sep = ",")
head(df)
df_cragg <- df[, c("Contribution.per.Capita", "colony", "log_Exports", "log_Population", "log_dist", "ND_Vulnerability")]
df_cragg <- na.omit(df_cragg)
df_cragg <- df_cragg %>% mutate_if(is.character,as.numeric)
str(df_cragg)
cragg_model <- mhurdle(Contribution.per.Capita ~ 1 + log_Population + colony + log_dist + log_Exports + ND_Vulnerability | 1 + log_Population + colony + log_dist + log_Exports + ND_Vulnerability, df_cragg, dist = "l", scaled = FALSE, corr = FALSE, h2 = FALSE)
print(summary(cragg_model))
df_cragg <- df[, c('Contribution.per.Capita','log_Population', 'colony', 'log_dist', 'log_Exports', 'ND_Exposure', 'ND_Sensitivity', 'ND_Governance', 'ND_Adaptive.Capacity')]
df_cragg <- df_cragg %>% mutate_if(is.character,as.numeric)
df_cragg$ND_Governance2 <- df_cragg$ND_Governance ** 2
df_cragg <- na.omit(df_cragg)
str(df_cragg)
cragg_model2 <- mhurdle(Contribution.per.Capita ~ 1 + log_Population + colony + log_dist + log_Exports + ND_Exposure + ND_Sensitivity + ND_Adaptive.Capacity + ND_Governance + ND_Governance2 | 1 + log_Population + colony + log_dist + log_Exports + ND_Exposure + ND_Sensitivity + ND_Adaptive.Capacity + ND_Governance + ND_Governance2, df_cragg, dist = "l", scaled = FALSE, corr = FALSE, h2 = FALSE)
print(summary(cragg_model2))
vuongtest(cragg_model, cragg_model2, type = "overlapping")
df_cragg <- df[, c('Contribution.per.Capita','log_Population', 'colony', 'log_dist', 'log_Exports', 'ND_Exposure', 'ND_Sensitivity', 'ND_Governance', 'ND_Adaptive.Capacity', 'ND_Vulnerability')]
df_cragg <- df_cragg %>% mutate_if(is.character,as.numeric)
df_cragg$ND_Governance2 <- df_cragg$ND_Governance ** 2
df_cragg <- na.omit(df_cragg)
str(df_cragg)
cragg_model <- mhurdle(Contribution.per.Capita ~ 1 + log_Population + colony + log_dist + log_Exports + ND_Vulnerability | 1 + log_Population + colony + log_dist + log_Exports + ND_Vulnerability, df_cragg, dist = "l", scaled = FALSE, corr = FALSE, h2 = FALSE)
print(summary(cragg_model))
cragg_model2 <- mhurdle(Contribution.per.Capita ~ 1 + log_Population + colony + log_dist + log_Exports + ND_Exposure + ND_Sensitivity + ND_Adaptive.Capacity + ND_Governance + ND_Governance2 | 1 + log_Population + colony + log_dist + log_Exports + ND_Exposure + ND_Sensitivity + ND_Adaptive.Capacity + ND_Governance + ND_Governance2, df_cragg, dist = "l", scaled = FALSE, corr = FALSE, h2 = FALSE)
print(summary(cragg_model2))
vuongtest(cragg_model, cragg_model2, type = "overlapping")
knitr::opts_chunk$set(echo = TRUE)
install.packages('truncreg')
knitr::opts_chunk$set(echo = TRUE)
library(truncreg)
library(tidyverse)
library(texreg)
library(truncreg)
library(tidyverse)
library(texreg)
setwd("C:/Users/timda/repo/thesis/Adaptation_Vulnerability")
df <- read.csv2('gcf_clean')
df <- read.csv2('gcf_clean', sep = ',')
df <- read.csv2('gcf_clean', sep = ',')
head(df)
trunc_model = truncreg(Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, point = 0, direction = 'left')
df <- read.csv2('gcf_clean', sep = ',')
head(df)
trunc_model = truncreg(Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, point = 0, direction = 'left', data = df)
df_trunc <- df[["Contribution_per_Capita", "gcf", "log_Population", "log_Exports", "ND-Vulnerability", "gcf_Vulnerability"]]
df_trunc <- df[,c("Contribution_per_Capita", "gcf", "log_Population", "log_Exports", "ND-Vulnerability", "gcf_Vulnerability")]
df_trunc <- df[,c("Contribution_per_Capita", "gcf", "log_Population", "log_Exports", "ND_Vulnerability", "gcf_Vulnerability")]
df_trunc <- df_trunc %>% mutate_if(is.character,as.numeric)
trunc_model = truncreg(Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, point = 0, direction = 'left', data = df)
trunc_model = truncreg(Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, point = 0, direction = 'left', data = df_trunc)
summary(trunc_model)
df_trunc <- df[,c("Contribution_per_Capita", "gcf", "log_Population", "log_Exports", "ND_Vulnerability", "gcf_Vulnerability")]
df_trunc <- df_trunc %>% mutate_if(is.character,as.numeric)
df_trunc$log_Contribution_per_Capita <- log(df_trunc$Contribution_per_Capita)
trunc_model = truncreg(log_Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, point = 0, direction = 'left', data = df_trunc)
model <- lm(log_Contribution_per_Capita ~ 1 + gcf + log_Population + log_Exports + ND_Vulnerability + gcf_Vulnerability, data = df_trunc)
summary(model)
